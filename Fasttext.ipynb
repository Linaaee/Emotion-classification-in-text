{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fasttext.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"7f07ea6121238a4c2b48c7789cd89259edf78930e8eb3a8b92e1567ae1a8d658"},"kernelspec":{"display_name":"Python 3.9.0 64-bit","name":"python3"},"language_info":{"name":"python","version":""},"metadata":{"interpreter":{"hash":"7f07ea6121238a4c2b48c7789cd89259edf78930e8eb3a8b92e1567ae1a8d658"}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84TW6cD8NOkA","outputId":"277f97db-3ea6-46dd-85e0-c9a7d4e6389f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKllHcbGpAoz","outputId":"513b33b9-aef0-4880-9d2c-ef322665c99e"},"source":["pip install fasttext"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting fasttext\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n","\r\u001b[K     |████▊                           | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.7.0)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3095092 sha256=0006c789d703062cb58942bd2e96d942c92d5281453c8c49ca67ec653fcd4558\n","  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8kExtcIh-yy","outputId":"2a92d692-2377-4d6d-f74e-e46f76e176a9"},"source":["pip install neattext"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting neattext\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/ac/f858b75b2d479d39cb43d92a21b892510b52240b27b48614a8da18e738b7/neattext-0.1.0-py3-none-any.whl (112kB)\n","\r\u001b[K     |███                             | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 20kB 28.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 30kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 40kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 102kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 9.4MB/s \n","\u001b[?25hInstalling collected packages: neattext\n","Successfully installed neattext-0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Zak34AuW60-"},"source":["import pandas as pd\n","import string #Opérations courantes sur les chaînes\n","import re   # pour utiliser  des expressions régulières ex:$\n","import nltk #boites outils ntk\n","from sklearn.model_selection import train_test_split\n","import neattext as nt\n","import neattext.functions as nfx\n","from neattext import TextCleaner as tc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrIs4Vn0W61V"},"source":["#Cleaning & Preprocessing\n","def process(text):\n","# la normalisation\n","    regex = re.compile(r'[إأٱآا]') #sauvegarder l'expression réguliere (r=expression reguliere)\n","    text = re.sub(regex, 'ا', str(text)) #remblacer des expressions par d'autres dans varia texte\n","    regex = re.compile(r'[ى]')\n","    text = re.sub(regex, 'ي', str(text))\n","    regex = re.compile(r'[ؤئ]')\n","    text = re.sub(regex, 'ء', str(text))\n","    text = re.sub('\\n', ' ', str(text))\n","    text = re.sub(' و ', ' ', str(text))\n","    text = re.sub(r'\\s*[A-Za-z]+\\b', '' , text)\n","    text = text.rstrip()\n","#supprimer les diacritiques\n","    arabic_diacritics = re.compile(\"\"\"\n","                             ّ    | # Shadda\n","                             َ    | # Fatha\n","                             ً    | # Tanwin Fath\n","                             ُ    | # Damma\n","                             ٌ    | # Tanwin Damm\n","                             ِ    | # Kasra\n","                             ٍ    | # Tanwin Kasr\n","                             ْ    | # Sukun\n","                             ـ     # Tatwil/Kashida\n","                         \"\"\", re.VERBOSE)   #verbose: séparer visuellement les expre et ajouter des commentaires\n","    text = re.sub(arabic_diacritics, '', text)\n","    \n","\n","#supprimer les ponctuations\n","    #liste des ponctuations arabe et anglais qu'on veut supprimer\n","    arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''    # utiliser ''' :multiples caractére de chaine\n","    english_punctuations = string.punctuation              #(!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~)\n","    punctuations_list = arabic_punctuations + english_punctuations\n","    #table de mappage\n","    translator = str.maketrans('','', punctuations_list) # le 1er elem a remplacer/le 2eme le remplacement,3eme=supprimer\n","    text= text.translate(translator) #chaine ou les caractere sont remplacé par d'autres dns table de mappage\n","\n","#supprimer les chaines répétés\n","    text=re.sub(r'(.)\\1+', r'\\1', str(text)) \n","\n","#supprimer les mots vides\n","    stopwords=nltk.corpus.stopwords.words('arabic') #les mots vides en arabe\n","    txt=[word for word in text if word not in stopwords]\n","\n","#supprimer les émojis\n","    myre = re.compile(u'['\n","    u'\\U0001F300-\\U0001F64F'\n","    u'\\U0001F680-\\U0001F6FF'     \n","    u'\\u2600-\\u26FF\\u2700-\\u27BF]+', re.UNICODE)\n","    text=myre.sub('', text)\n","    \n","    \n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MvlR6tuiW61b"},"source":["filename='new_db.xlsx'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrPrOcR8W61e"},"source":["#Importer le fichier excel\n","data=pd.read_excel(filename) #filename:le chemin d'acces au fichier excel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lppk2WGVX9d3","outputId":"016f6949-1875-45a7-eb56-7bdb5ac129c4"},"source":["nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"f4q74R2UW61g"},"source":["#Cleaning DB\n","data['TWEET'] = data['TWEET'].apply(process)\n","data['TWEET'] = data['TWEET'].apply(nfx.remove_hashtags)\n","data['TWEET'] = data['TWEET'].apply(nfx.remove_userhandles)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnO3IgbU2uxT"},"source":["index=[]\n","for i in range(len(data)):\n","  if data.iloc[i].TWEET=='':\n","    index.append(i)\n","\n","for i in index:\n","  data=data.drop(i)\n","data = data.reset_index().drop('index',axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"_sL2AJV4W61i","outputId":"77de63e7-10c9-4cac-8854-eae0341853d7"},"source":["#Affichage des premiers elts\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TWEET</th>\n","      <th>LABEL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>الاوليمبياد الجايه هكون لسه ف الكليه</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>عجز الموازنه وصل ل937 من الناتج المحلي يعني لس...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>كتنا نيله ف حظنا الهباب</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>جميعنا نريد تحقيق اهدافنا لكن تونس تالقت في حر...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>الاوليمبياد نظامها مختلف ومواعيد المونديال مكا...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               TWEET  LABEL\n","0               الاوليمبياد الجايه هكون لسه ف الكليه      0\n","1  عجز الموازنه وصل ل937 من الناتج المحلي يعني لس...      1\n","2                            كتنا نيله ف حظنا الهباب      2\n","3  جميعنا نريد تحقيق اهدافنا لكن تونس تالقت في حر...      3\n","4  الاوليمبياد نظامها مختلف ومواعيد المونديال مكا...      0"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"gF9b7Yb6W61m","scrolled":true,"outputId":"6d6077bf-07e7-47e3-abdd-0a230682f06a"},"source":["#Affichage des derniers elts\n","data.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TWEET</th>\n","      <th>LABEL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>29947</th>\n","      <td>اتمني تعملو بطاقات خاصة او ذهبية لعملاء الداءم...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>29948</th>\n","      <td>المشويات عندهم اطيب مشويات اكلتها بحياتي والاس...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>29949</th>\n","      <td>المطعم متاز لغايه من ناحيه تجهيزات المطعم وايض...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>29950</th>\n","      <td>جينا عندهم الساعة 10 باليل مافي احد اتبرع يشوف...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>29951</th>\n","      <td>اذا كان الي بالشارع التجاري اوه ماشاء اله واله...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   TWEET  LABEL\n","29947  اتمني تعملو بطاقات خاصة او ذهبية لعملاء الداءم...      3\n","29948  المشويات عندهم اطيب مشويات اكلتها بحياتي والاس...      3\n","29949  المطعم متاز لغايه من ناحيه تجهيزات المطعم وايض...      3\n","29950  جينا عندهم الساعة 10 باليل مافي احد اتبرع يشوف...      1\n","29951  اذا كان الي بالشارع التجاري اوه ماشاء اله واله...      3"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"riI30SSasa_L"},"source":["#Remplacer chaque label par un entier\n","encode_dict = {}\n","\n","def encode_cat(x):\n","    if x not in encode_dict.keys():\n","        encode_dict[x]=len(encode_dict)\n","    return encode_dict[x]\n","\n","data['LABEL'] = data['LABEL'].apply(lambda x: encode_cat(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XRiie2x8W61p","outputId":"3a720e4e-6ad9-40d4-b260-b157c40c247c"},"source":["#Split data into random train(70%) and test(30%) subsets\n","text_train, text_test, label_train, label_test = train_test_split(data.TWEET,data.LABEL,test_size=0.20, random_state=42)\n","print(text_train.shape,text_test.shape,label_train.shape,label_test.shape)  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["(23961,) (5991,) (23961,) (5991,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sry5o4BwW61_"},"source":["# FASTTEXT"]},{"cell_type":"markdown","metadata":{"id":"tduOX-xj94X6"},"source":["# Preparation du model"]},{"cell_type":"code","metadata":{"id":"T-yxUqxaW62A"},"source":["import fasttext"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArCPcUI8gUYB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba7af386-2cfe-48fa-b988-4ef4d77624eb"},"source":["# load AraVec Spacy model\n","%cd /content/drive/MyDrive/fasttext\n","ft = fasttext.load_model('cc.ar.300.bin')\n","%cd ..\n","%cd ..\n","%cd .."],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/fasttext\n","/content/drive/My Drive\n","/content/drive\n","/content\n"],"name":"stdout"},{"output_type":"stream","text":["Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"eOmYpTi399AI"},"source":["# Machine learning"]},{"cell_type":"code","metadata":{"id":"FqJtBj6b_VMe"},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn import svm\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPpHEnwo-F8D"},"source":["def get_vect(word, model):\n","    try:\n","        return model[word]\n","    except KeyError:\n","        return np.zeros((model.get_dimension(),))\n","\n","def sum_vectors(phrase, model):\n","    sen=phrase.split()\n","    return sum([get_vect(w, model) for w in sen])\n","\n","def fasttext_features_pred(phrase, model):\n","    sen=phrase.split()\n","    somme_vec=sum([get_vect(w, model) for w in sen])\n","    if isinstance(somme_vec,int):\n","        return np.zeros((model.get_dimension(),))\n","    else:\n","        return somme_vec\n","\n","def fasttext_features(X, model):\n","    liste=[]\n","    for p in X:\n","        somme_vec=sum_vectors(p, model)\n","        if isinstance(somme_vec,int):\n","            liste.append(np.zeros((model.get_dimension(),)))\n","        else:\n","            liste.append(somme_vec)\n","    return np.vstack(liste)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lT0ia2vf-URH"},"source":["# Get the sentence embeddings for the train and test dataset\n","ft_train_feat = fasttext_features(text_train, ft)\n","ft_test_feat = fasttext_features(text_test, ft)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0F1mgZor-W6B","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e63a584a-7206-4762-e673-363abdac4141"},"source":["# create the model, train it, print scores\n","lrft = LogisticRegression(solver='liblinear',max_iter=3000)\n","lrft.fit(ft_train_feat, label_train)\n","tag_pred = lrft.predict(ft_test_feat)\n","print(classification_report(label_test, tag_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.59      0.65      0.62       314\n","           1       0.67      0.57      0.62      1184\n","           2       0.54      0.38      0.45       701\n","           3       0.69      0.90      0.78      2434\n","           4       0.45      0.21      0.29       470\n","           5       0.65      0.50      0.56       381\n","           6       0.73      0.66      0.69       231\n","           7       0.84      0.80      0.82       276\n","\n","    accuracy                           0.67      5991\n","   macro avg       0.64      0.58      0.60      5991\n","weighted avg       0.65      0.67      0.65      5991\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmHoLzdG-vqs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d094dd53-b70c-4f2b-abde-376235e86f88"},"source":["# create the model, train it, print scores\n","SVM=svm.SVC()\n","SVM.fit(ft_train_feat,label_train)\n","tag_pred = SVM.predict(ft_test_feat)\n","print(classification_report(label_test, tag_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.55      0.66      0.60       314\n","           1       0.67      0.67      0.67      1184\n","           2       0.55      0.37      0.44       701\n","           3       0.69      0.91      0.78      2434\n","           4       0.58      0.16      0.25       470\n","           5       0.76      0.51      0.61       381\n","           6       0.78      0.61      0.68       231\n","           7       0.93      0.67      0.78       276\n","\n","    accuracy                           0.68      5991\n","   macro avg       0.69      0.57      0.60      5991\n","weighted avg       0.67      0.68      0.65      5991\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DWT_L556-y49","colab":{"base_uri":"https://localhost:8080/"},"outputId":"790b9492-0e83-474f-e902-a17c9abc3b7f"},"source":["# create the model, train it, print scores\n","rf=RandomForestClassifier()\n","rf.fit(ft_train_feat,label_train)\n","tag_pred = rf.predict(ft_test_feat)\n","print(classification_report(label_test, tag_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.54      0.57      0.55       314\n","           1       0.74      0.78      0.76      1184\n","           2       0.76      0.54      0.63       701\n","           3       0.77      0.93      0.84      2434\n","           4       0.77      0.51      0.61       470\n","           5       0.73      0.59      0.65       381\n","           6       0.77      0.54      0.63       231\n","           7       0.88      0.55      0.67       276\n","\n","    accuracy                           0.75      5991\n","   macro avg       0.74      0.63      0.67      5991\n","weighted avg       0.75      0.75      0.74      5991\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hymRP8Zr_NpO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff317cbc-99d5-4127-d608-b0d2bfb1d89b"},"source":["# create the model, train it, print scores\n","nb=GaussianNB()\n","nb.fit(ft_train_feat,label_train)\n","tag_pred = nb.predict(ft_test_feat)\n","print(classification_report(label_test, tag_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.10      0.88      0.18       314\n","           1       0.47      0.29      0.36      1184\n","           2       0.18      0.05      0.07       701\n","           3       0.60      0.30      0.40      2434\n","           4       0.16      0.02      0.03       470\n","           5       0.28      0.07      0.11       381\n","           6       0.25      0.23      0.24       231\n","           7       0.12      0.34      0.18       276\n","\n","    accuracy                           0.26      5991\n","   macro avg       0.27      0.27      0.20      5991\n","weighted avg       0.41      0.26      0.28      5991\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aWZ3jeQV-GaG"},"source":["# Deep Learning"]},{"cell_type":"code","metadata":{"id":"rRAELyZ7uHPs"},"source":["from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Dense\n","from keras.layers import *\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing.text import Tokenizer\n","import numpy as np\n","from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2Iux4mCvfzS"},"source":["#create a word-to-index dictionary\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(text_train)\n","\n","X_train = tokenizer.texts_to_sequences(text_train)\n","X_test = tokenizer.texts_to_sequences(text_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCtB910KvkwO"},"source":["# Adding 1 because of reserved 0 index\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","#Set the maximum size of each list to 82\n","maxlen = 82\n","\n","#Add 0 at the end of the list until it reaches the max length\n","X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n","X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IROfwITsvu6a"},"source":["#Create an embedding matrix where each row number will correspond to the index of the word in the corpus\n","embedding_matrix = np.zeros((vocab_size, 300))\n","for word, index in tokenizer.word_index.items():\n","    embedding_vector = ft[word]\n","    if embedding_vector is not None:\n","        embedding_matrix[index] = embedding_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCLHcM0LzKUY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7--3gBcwLNa"},"source":["#--------------------------------------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TUhRdqYA3JY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"84ae51bc-9e6f-47ba-b1f4-a3bd793f5a81"},"source":["model1 = Sequential()\n","embedding_layer = Embedding(vocab_size,300 , weights=[embedding_matrix], input_length=maxlen , trainable=False)\n","model1.add(embedding_layer)\n","\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n","model1.add(GRU(256, activation='sigmoid',recurrent_activation='sigmoid' , return_sequences=True))\n","\n","# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n","model1.add(SimpleRNN(128))\n","\n","\n","model1.add(Dense(8, activation='sigmoid'))\n","model1.compile(optimizer='Adamax', loss='sparse_categorical_crossentropy', metrics=['acc'])\n","model1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 82, 300)           19754700  \n","_________________________________________________________________\n","gru (GRU)                    (None, 82, 256)           428544    \n","_________________________________________________________________\n","simple_rnn (SimpleRNN)       (None, 128)               49280     \n","_________________________________________________________________\n","dense (Dense)                (None, 8)                 1032      \n","=================================================================\n","Total params: 20,233,556\n","Trainable params: 478,856\n","Non-trainable params: 19,754,700\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gYx0n-PHKFNr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f27d8e6-2c50-4434-9035-d26fb023b635"},"source":["history = model1.fit(X_train, label_train, batch_size=128, epochs=30, verbose=1, validation_split=0.2)\n","\n","score = model1.evaluate(X_test, label_test, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","150/150 [==============================] - 60s 246ms/step - loss: 1.7910 - acc: 0.3832 - val_loss: 1.7262 - val_acc: 0.4129\n","Epoch 2/30\n","150/150 [==============================] - 36s 243ms/step - loss: 1.7261 - acc: 0.4172 - val_loss: 1.6913 - val_acc: 0.4356\n","Epoch 3/30\n","150/150 [==============================] - 34s 230ms/step - loss: 1.6946 - acc: 0.4272 - val_loss: 1.6296 - val_acc: 0.4352\n","Epoch 4/30\n","150/150 [==============================] - 36s 243ms/step - loss: 1.6226 - acc: 0.4333 - val_loss: 1.5487 - val_acc: 0.4502\n","Epoch 5/30\n","150/150 [==============================] - 34s 230ms/step - loss: 1.5324 - acc: 0.4476 - val_loss: 1.4960 - val_acc: 0.4534\n","Epoch 6/30\n","150/150 [==============================] - 36s 242ms/step - loss: 1.4784 - acc: 0.4542 - val_loss: 1.4215 - val_acc: 0.4936\n","Epoch 7/30\n","150/150 [==============================] - 37s 246ms/step - loss: 1.4451 - acc: 0.4792 - val_loss: 1.3964 - val_acc: 0.4976\n","Epoch 8/30\n","150/150 [==============================] - 35s 235ms/step - loss: 1.4160 - acc: 0.4856 - val_loss: 1.3344 - val_acc: 0.5055\n","Epoch 9/30\n","150/150 [==============================] - 36s 240ms/step - loss: 1.3495 - acc: 0.5124 - val_loss: 1.2803 - val_acc: 0.5270\n","Epoch 10/30\n","150/150 [==============================] - 36s 239ms/step - loss: 1.3034 - acc: 0.5292 - val_loss: 1.2755 - val_acc: 0.5506\n","Epoch 11/30\n","150/150 [==============================] - 36s 238ms/step - loss: 1.2803 - acc: 0.5484 - val_loss: 1.2615 - val_acc: 0.5431\n","Epoch 12/30\n","150/150 [==============================] - 36s 238ms/step - loss: 1.2318 - acc: 0.5594 - val_loss: 1.2085 - val_acc: 0.5600\n","Epoch 13/30\n","150/150 [==============================] - 35s 235ms/step - loss: 1.2307 - acc: 0.5545 - val_loss: 1.1847 - val_acc: 0.5675\n","Epoch 14/30\n","150/150 [==============================] - 36s 238ms/step - loss: 1.1733 - acc: 0.5780 - val_loss: 1.1622 - val_acc: 0.5827\n","Epoch 15/30\n","150/150 [==============================] - 35s 231ms/step - loss: 1.1424 - acc: 0.5918 - val_loss: 1.0924 - val_acc: 0.6098\n","Epoch 16/30\n","150/150 [==============================] - 36s 243ms/step - loss: 1.1227 - acc: 0.6057 - val_loss: 1.0887 - val_acc: 0.6132\n","Epoch 17/30\n","150/150 [==============================] - 36s 242ms/step - loss: 1.0831 - acc: 0.6162 - val_loss: 1.0753 - val_acc: 0.6134\n","Epoch 18/30\n","150/150 [==============================] - 34s 228ms/step - loss: 1.0629 - acc: 0.6244 - val_loss: 1.0481 - val_acc: 0.6290\n","Epoch 19/30\n","150/150 [==============================] - 36s 241ms/step - loss: 1.0584 - acc: 0.6219 - val_loss: 1.0527 - val_acc: 0.6240\n","Epoch 20/30\n","150/150 [==============================] - 34s 227ms/step - loss: 1.0495 - acc: 0.6287 - val_loss: 1.0762 - val_acc: 0.6107\n","Epoch 21/30\n","150/150 [==============================] - 36s 240ms/step - loss: 1.0176 - acc: 0.6392 - val_loss: 1.0241 - val_acc: 0.6299\n","Epoch 22/30\n","150/150 [==============================] - 34s 227ms/step - loss: 1.0027 - acc: 0.6450 - val_loss: 1.0873 - val_acc: 0.6113\n","Epoch 23/30\n","150/150 [==============================] - 36s 237ms/step - loss: 0.9827 - acc: 0.6498 - val_loss: 0.9924 - val_acc: 0.6520\n","Epoch 24/30\n","150/150 [==============================] - 35s 231ms/step - loss: 0.9743 - acc: 0.6592 - val_loss: 1.0239 - val_acc: 0.6274\n","Epoch 25/30\n","150/150 [==============================] - 36s 241ms/step - loss: 0.9538 - acc: 0.6626 - val_loss: 1.0097 - val_acc: 0.6445\n","Epoch 26/30\n","150/150 [==============================] - 35s 233ms/step - loss: 0.9592 - acc: 0.6610 - val_loss: 0.9854 - val_acc: 0.6495\n","Epoch 27/30\n","150/150 [==============================] - 35s 235ms/step - loss: 0.9374 - acc: 0.6687 - val_loss: 0.9611 - val_acc: 0.6553\n","Epoch 28/30\n","150/150 [==============================] - 35s 232ms/step - loss: 0.9445 - acc: 0.6641 - val_loss: 0.9980 - val_acc: 0.6401\n","Epoch 29/30\n","150/150 [==============================] - 36s 242ms/step - loss: 0.9332 - acc: 0.6686 - val_loss: 0.9347 - val_acc: 0.6697\n","Epoch 30/30\n","150/150 [==============================] - 34s 229ms/step - loss: 0.9101 - acc: 0.6817 - val_loss: 0.9177 - val_acc: 0.6720\n","188/188 [==============================] - 4s 21ms/step - loss: 0.9264 - acc: 0.6777\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FE4vsQRPjlvo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1dc6e45-6ba9-432c-bef6-de4dc0996a91"},"source":["print(\"Test Score:\", score[0])\n","print(\"Test Accuracy:\", score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Score: 0.9263944029808044\n","Test Accuracy: 0.6776831746101379\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XssBQy3zjpVo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e8596ea-5227-44f8-9c08-4b6737753168"},"source":["pred = np.argmax(model1.predict(X_test), axis=-1)\n","print(classification_report(label_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.56      0.61      0.58       314\n","           1       0.59      0.68      0.63      1184\n","           2       0.64      0.34      0.44       701\n","           3       0.75      0.87      0.81      2434\n","           4       0.39      0.24      0.30       470\n","           5       0.67      0.56      0.61       381\n","           6       0.64      0.73      0.68       231\n","           7       0.95      0.81      0.87       276\n","\n","    accuracy                           0.68      5991\n","   macro avg       0.65      0.60      0.62      5991\n","weighted avg       0.67      0.68      0.66      5991\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0HmRf6g6Kexi"},"source":["#----------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"onyMwlc7VUtk"},"source":["model2 = Sequential()\n","embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n","model2.add(embedding_layer)\n","\n","model2.add(LSTM(1024))\n","\n","model2.add(Dense(8, activation='softmax'))\n","model2.compile(optimizer='Adamax', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXpRpNJmW3FH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9017278-87aa-4736-dcfe-9b445b40f335"},"source":["history = model2.fit(X_train, label_train, batch_size=128, epochs=100, verbose=1, validation_split=0.2)\n","\n","score = model2.evaluate(X_test, label_test, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","150/150 [==============================] - 20s 114ms/step - loss: 1.8880 - acc: 0.4021 - val_loss: 1.4875 - val_acc: 0.4586\n","Epoch 2/100\n","150/150 [==============================] - 17s 112ms/step - loss: 1.4631 - acc: 0.4649 - val_loss: 1.3197 - val_acc: 0.5291\n","Epoch 3/100\n","150/150 [==============================] - 17s 114ms/step - loss: 1.3454 - acc: 0.5251 - val_loss: 1.3265 - val_acc: 0.5320\n","Epoch 4/100\n","150/150 [==============================] - 17s 116ms/step - loss: 1.3035 - acc: 0.5398 - val_loss: 1.2712 - val_acc: 0.5452\n","Epoch 5/100\n","150/150 [==============================] - 18s 118ms/step - loss: 1.2557 - acc: 0.5473 - val_loss: 1.2342 - val_acc: 0.5602\n","Epoch 6/100\n","150/150 [==============================] - 18s 117ms/step - loss: 1.2458 - acc: 0.5520 - val_loss: 1.2402 - val_acc: 0.5591\n","Epoch 7/100\n","150/150 [==============================] - 17s 115ms/step - loss: 1.2228 - acc: 0.5671 - val_loss: 1.1918 - val_acc: 0.5786\n","Epoch 8/100\n","150/150 [==============================] - 17s 116ms/step - loss: 1.2022 - acc: 0.5727 - val_loss: 1.2251 - val_acc: 0.5717\n","Epoch 9/100\n","150/150 [==============================] - 17s 116ms/step - loss: 1.1710 - acc: 0.5852 - val_loss: 1.1867 - val_acc: 0.5786\n","Epoch 10/100\n","150/150 [==============================] - 17s 116ms/step - loss: 1.1348 - acc: 0.6011 - val_loss: 1.1174 - val_acc: 0.6140\n","Epoch 11/100\n","150/150 [==============================] - 18s 117ms/step - loss: 1.1138 - acc: 0.6118 - val_loss: 1.1545 - val_acc: 0.6038\n","Epoch 12/100\n","150/150 [==============================] - 17s 117ms/step - loss: 1.0975 - acc: 0.6173 - val_loss: 1.1073 - val_acc: 0.6036\n","Epoch 13/100\n","150/150 [==============================] - 18s 117ms/step - loss: 1.0715 - acc: 0.6318 - val_loss: 1.0772 - val_acc: 0.6132\n","Epoch 14/100\n","150/150 [==============================] - 17s 117ms/step - loss: 1.0554 - acc: 0.6357 - val_loss: 1.0705 - val_acc: 0.6247\n","Epoch 15/100\n","150/150 [==============================] - 17s 116ms/step - loss: 1.0449 - acc: 0.6403 - val_loss: 1.1634 - val_acc: 0.5769\n","Epoch 16/100\n","150/150 [==============================] - 17s 116ms/step - loss: 1.0641 - acc: 0.6262 - val_loss: 1.1064 - val_acc: 0.6232\n","Epoch 17/100\n","150/150 [==============================] - 17s 116ms/step - loss: 1.0227 - acc: 0.6413 - val_loss: 1.0907 - val_acc: 0.6261\n","Epoch 18/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.9857 - acc: 0.6536 - val_loss: 1.0492 - val_acc: 0.6270\n","Epoch 19/100\n","150/150 [==============================] - 17s 116ms/step - loss: 1.0125 - acc: 0.6432 - val_loss: 1.0511 - val_acc: 0.6301\n","Epoch 20/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.9871 - acc: 0.6528 - val_loss: 1.0583 - val_acc: 0.6301\n","Epoch 21/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.9776 - acc: 0.6576 - val_loss: 1.0667 - val_acc: 0.6386\n","Epoch 22/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.9640 - acc: 0.6593 - val_loss: 1.0215 - val_acc: 0.6366\n","Epoch 23/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.9617 - acc: 0.6653 - val_loss: 1.0273 - val_acc: 0.6372\n","Epoch 24/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.9544 - acc: 0.6699 - val_loss: 1.0124 - val_acc: 0.6495\n","Epoch 25/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.9243 - acc: 0.6783 - val_loss: 1.0144 - val_acc: 0.6470\n","Epoch 26/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.9181 - acc: 0.6830 - val_loss: 0.9924 - val_acc: 0.6551\n","Epoch 27/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.9064 - acc: 0.6951 - val_loss: 0.9873 - val_acc: 0.6637\n","Epoch 28/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.8942 - acc: 0.6912 - val_loss: 1.0133 - val_acc: 0.6595\n","Epoch 29/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.9011 - acc: 0.6909 - val_loss: 0.9871 - val_acc: 0.6637\n","Epoch 30/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.8681 - acc: 0.7009 - val_loss: 0.9632 - val_acc: 0.6722\n","Epoch 31/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.8739 - acc: 0.7024 - val_loss: 0.9814 - val_acc: 0.6704\n","Epoch 32/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.8556 - acc: 0.7112 - val_loss: 0.9610 - val_acc: 0.6681\n","Epoch 33/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.8624 - acc: 0.7075 - val_loss: 0.9478 - val_acc: 0.6785\n","Epoch 34/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.8469 - acc: 0.7125 - val_loss: 0.9521 - val_acc: 0.6850\n","Epoch 35/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.8287 - acc: 0.7206 - val_loss: 0.9398 - val_acc: 0.6891\n","Epoch 36/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.7974 - acc: 0.7342 - val_loss: 0.9223 - val_acc: 0.6898\n","Epoch 37/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.7715 - acc: 0.7441 - val_loss: 0.9264 - val_acc: 0.6952\n","Epoch 38/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.7591 - acc: 0.7480 - val_loss: 0.9487 - val_acc: 0.6887\n","Epoch 39/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.7604 - acc: 0.7494 - val_loss: 0.9311 - val_acc: 0.6810\n","Epoch 40/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.7610 - acc: 0.7510 - val_loss: 0.9199 - val_acc: 0.6983\n","Epoch 41/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.7316 - acc: 0.7599 - val_loss: 0.9229 - val_acc: 0.6933\n","Epoch 42/100\n","150/150 [==============================] - 19s 124ms/step - loss: 0.7229 - acc: 0.7565 - val_loss: 0.9217 - val_acc: 0.6881\n","Epoch 43/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.7184 - acc: 0.7643 - val_loss: 0.9066 - val_acc: 0.7075\n","Epoch 44/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.6782 - acc: 0.7801 - val_loss: 0.8966 - val_acc: 0.7077\n","Epoch 45/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.6792 - acc: 0.7777 - val_loss: 0.9168 - val_acc: 0.7002\n","Epoch 46/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.6694 - acc: 0.7852 - val_loss: 0.9129 - val_acc: 0.7079\n","Epoch 47/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.6759 - acc: 0.7763 - val_loss: 0.8993 - val_acc: 0.7117\n","Epoch 48/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.6152 - acc: 0.7980 - val_loss: 0.9112 - val_acc: 0.6962\n","Epoch 49/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.6288 - acc: 0.7932 - val_loss: 0.9336 - val_acc: 0.7081\n","Epoch 50/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.5930 - acc: 0.8055 - val_loss: 0.9160 - val_acc: 0.7048\n","Epoch 51/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.5948 - acc: 0.8056 - val_loss: 0.8765 - val_acc: 0.7198\n","Epoch 52/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.5600 - acc: 0.8199 - val_loss: 0.9279 - val_acc: 0.7131\n","Epoch 53/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.5667 - acc: 0.8181 - val_loss: 0.8885 - val_acc: 0.7217\n","Epoch 54/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.5133 - acc: 0.8350 - val_loss: 0.9128 - val_acc: 0.7217\n","Epoch 55/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.5163 - acc: 0.8358 - val_loss: 0.9115 - val_acc: 0.7177\n","Epoch 56/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.5021 - acc: 0.8425 - val_loss: 0.9085 - val_acc: 0.7292\n","Epoch 57/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.4900 - acc: 0.8431 - val_loss: 0.9151 - val_acc: 0.7225\n","Epoch 58/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.4781 - acc: 0.8468 - val_loss: 0.9283 - val_acc: 0.7240\n","Epoch 59/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.4529 - acc: 0.8607 - val_loss: 0.9433 - val_acc: 0.7254\n","Epoch 60/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.4393 - acc: 0.8618 - val_loss: 0.9296 - val_acc: 0.7352\n","Epoch 61/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.4226 - acc: 0.8660 - val_loss: 0.9539 - val_acc: 0.7242\n","Epoch 62/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.4250 - acc: 0.8648 - val_loss: 0.9355 - val_acc: 0.7430\n","Epoch 63/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.3827 - acc: 0.8811 - val_loss: 0.9219 - val_acc: 0.7432\n","Epoch 64/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.3714 - acc: 0.8844 - val_loss: 0.9515 - val_acc: 0.7436\n","Epoch 65/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.3656 - acc: 0.8897 - val_loss: 0.9390 - val_acc: 0.7465\n","Epoch 66/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.3615 - acc: 0.8864 - val_loss: 0.9190 - val_acc: 0.7386\n","Epoch 67/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.3538 - acc: 0.8934 - val_loss: 0.9213 - val_acc: 0.7473\n","Epoch 68/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.3374 - acc: 0.8964 - val_loss: 0.9431 - val_acc: 0.7367\n","Epoch 69/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.3397 - acc: 0.8954 - val_loss: 0.9552 - val_acc: 0.7488\n","Epoch 70/100\n","150/150 [==============================] - 17s 116ms/step - loss: 0.3012 - acc: 0.9086 - val_loss: 0.9808 - val_acc: 0.7475\n","Epoch 71/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.3143 - acc: 0.9054 - val_loss: 1.0666 - val_acc: 0.7459\n","Epoch 72/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.3118 - acc: 0.9041 - val_loss: 0.9911 - val_acc: 0.7446\n","Epoch 73/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.2909 - acc: 0.9120 - val_loss: 1.0204 - val_acc: 0.7421\n","Epoch 74/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.2879 - acc: 0.9129 - val_loss: 0.9957 - val_acc: 0.7480\n","Epoch 75/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.2659 - acc: 0.9169 - val_loss: 1.0573 - val_acc: 0.7448\n","Epoch 76/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.2680 - acc: 0.9196 - val_loss: 1.0549 - val_acc: 0.7551\n","Epoch 77/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.2560 - acc: 0.9233 - val_loss: 1.0095 - val_acc: 0.7465\n","Epoch 78/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.2536 - acc: 0.9237 - val_loss: 1.1055 - val_acc: 0.7498\n","Epoch 79/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.1982 - acc: 0.9402 - val_loss: 1.1152 - val_acc: 0.7442\n","Epoch 80/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.2012 - acc: 0.9384 - val_loss: 1.1457 - val_acc: 0.7517\n","Epoch 81/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1929 - acc: 0.9415 - val_loss: 1.1422 - val_acc: 0.7469\n","Epoch 82/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1986 - acc: 0.9393 - val_loss: 1.1315 - val_acc: 0.7551\n","Epoch 83/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1886 - acc: 0.9441 - val_loss: 1.2018 - val_acc: 0.7469\n","Epoch 84/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1801 - acc: 0.9448 - val_loss: 1.1591 - val_acc: 0.7536\n","Epoch 85/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1798 - acc: 0.9449 - val_loss: 1.1379 - val_acc: 0.7563\n","Epoch 86/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.1832 - acc: 0.9446 - val_loss: 1.1783 - val_acc: 0.7574\n","Epoch 87/100\n","150/150 [==============================] - 17s 117ms/step - loss: 0.1690 - acc: 0.9473 - val_loss: 1.1775 - val_acc: 0.7538\n","Epoch 88/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1953 - acc: 0.9369 - val_loss: 1.1610 - val_acc: 0.7574\n","Epoch 89/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1871 - acc: 0.9437 - val_loss: 1.1883 - val_acc: 0.7565\n","Epoch 90/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1692 - acc: 0.9491 - val_loss: 1.2222 - val_acc: 0.7553\n","Epoch 91/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1660 - acc: 0.9468 - val_loss: 1.1970 - val_acc: 0.7444\n","Epoch 92/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1519 - acc: 0.9534 - val_loss: 1.2053 - val_acc: 0.7515\n","Epoch 93/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1408 - acc: 0.9575 - val_loss: 1.2146 - val_acc: 0.7461\n","Epoch 94/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1356 - acc: 0.9593 - val_loss: 1.2789 - val_acc: 0.7465\n","Epoch 95/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1636 - acc: 0.9488 - val_loss: 1.1926 - val_acc: 0.7574\n","Epoch 96/100\n","150/150 [==============================] - 18s 118ms/step - loss: 0.1457 - acc: 0.9547 - val_loss: 1.1994 - val_acc: 0.7486\n","Epoch 97/100\n","150/150 [==============================] - 18s 118ms/step - loss: 0.1405 - acc: 0.9555 - val_loss: 1.2830 - val_acc: 0.7521\n","Epoch 98/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1243 - acc: 0.9598 - val_loss: 1.2724 - val_acc: 0.7574\n","Epoch 99/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1106 - acc: 0.9642 - val_loss: 1.2798 - val_acc: 0.7540\n","Epoch 100/100\n","150/150 [==============================] - 18s 117ms/step - loss: 0.1334 - acc: 0.9571 - val_loss: 1.2409 - val_acc: 0.7609\n","188/188 [==============================] - 3s 14ms/step - loss: 1.2765 - acc: 0.7600\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RdpxiAJwXBN_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d6494f85-3e53-4996-dc48-95df887d6b8e"},"source":["print(\"Test Score:\", score[0])\n","print(\"Test Accuracy:\", score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Score: 1.276484727859497\n","Test Accuracy: 0.7599732875823975\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yia131MP2R9s","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0e4b276d-2f1e-4b3b-9014-3e0ad2611aed"},"source":["pred = np.argmax(model2.predict(X_test), axis=-1)\n","print(classification_report(label_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.59      0.67      0.63       314\n","           1       0.77      0.72      0.74      1184\n","           2       0.68      0.61      0.64       701\n","           3       0.84      0.87      0.86      2434\n","           4       0.54      0.60      0.57       470\n","           5       0.68      0.65      0.66       381\n","           6       0.76      0.78      0.77       231\n","           7       0.91      0.84      0.88       276\n","\n","    accuracy                           0.76      5991\n","   macro avg       0.72      0.72      0.72      5991\n","weighted avg       0.76      0.76      0.76      5991\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ldAVxwVa-nhh"},"source":["#------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwRMAfYRSDVh"},"source":["model3 = Sequential()\n","\n","embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n","model3.add(embedding_layer)\n","\n","\n","model3.add(Conv1D(1024, 1, activation='softsign'))\n","model3.add(Conv1D(1024, 1, activation='softsign'))\n","model3.add(GlobalMaxPooling1D())\n","model3.add(Dense(8, activation='softmax'))\n","model3.compile(optimizer='Adamax', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMP17ZoDSaDc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"58b2ab81-2382-4aa3-cd58-9b04515c605b"},"source":["history = model3.fit(X_train, label_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n","\n","score = model3.evaluate(X_test, label_test, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","150/150 [==============================] - 8s 41ms/step - loss: 1.4140 - acc: 0.5028 - val_loss: 0.9065 - val_acc: 0.6839\n","Epoch 2/10\n","150/150 [==============================] - 6s 37ms/step - loss: 0.8311 - acc: 0.7166 - val_loss: 0.7654 - val_acc: 0.7252\n","Epoch 3/10\n","150/150 [==============================] - 6s 37ms/step - loss: 0.7007 - acc: 0.7543 - val_loss: 0.7218 - val_acc: 0.7438\n","Epoch 4/10\n","150/150 [==============================] - 6s 38ms/step - loss: 0.6340 - acc: 0.7788 - val_loss: 0.6960 - val_acc: 0.7557\n","Epoch 5/10\n","150/150 [==============================] - 6s 38ms/step - loss: 0.5985 - acc: 0.7906 - val_loss: 0.6676 - val_acc: 0.7657\n","Epoch 6/10\n","150/150 [==============================] - 6s 38ms/step - loss: 0.5527 - acc: 0.8113 - val_loss: 0.6619 - val_acc: 0.7718\n","Epoch 7/10\n","150/150 [==============================] - 6s 38ms/step - loss: 0.5231 - acc: 0.8224 - val_loss: 0.6457 - val_acc: 0.7776\n","Epoch 8/10\n","150/150 [==============================] - 6s 37ms/step - loss: 0.4928 - acc: 0.8370 - val_loss: 0.6428 - val_acc: 0.7795\n","Epoch 9/10\n","150/150 [==============================] - 6s 37ms/step - loss: 0.4529 - acc: 0.8497 - val_loss: 0.6360 - val_acc: 0.7805\n","Epoch 10/10\n","150/150 [==============================] - 6s 37ms/step - loss: 0.4351 - acc: 0.8572 - val_loss: 0.6320 - val_acc: 0.7857\n","188/188 [==============================] - 1s 5ms/step - loss: 0.6810 - acc: 0.7782\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lPUYkPfOSa-w","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28f420bf-31ad-4d6a-9f7a-7bc4f69675a2"},"source":["print(\"Test Score:\", score[0])\n","print(\"Test Accuracy:\", score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Score: 0.6809646487236023\n","Test Accuracy: 0.7781672477722168\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9C3q6fL4zTf0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd5ff0ea-e83a-4d73-ea36-1e6220258674"},"source":["pred = np.argmax(model3.predict(X_test), axis=-1)\n","print(classification_report(label_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.62      0.84      0.71       314\n","           1       0.81      0.67      0.73      1184\n","           2       0.68      0.66      0.67       701\n","           3       0.84      0.90      0.87      2434\n","           4       0.63      0.55      0.59       470\n","           5       0.67      0.69      0.68       381\n","           6       0.79      0.80      0.80       231\n","           7       0.94      0.88      0.91       276\n","\n","    accuracy                           0.78      5991\n","   macro avg       0.75      0.75      0.74      5991\n","weighted avg       0.78      0.78      0.78      5991\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UCDPJDJDS3wG"},"source":["#--------------------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoAwPs5DNxJR"},"source":[""],"execution_count":null,"outputs":[]}]}