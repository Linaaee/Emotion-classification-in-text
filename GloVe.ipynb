{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "7f07ea6121238a4c2b48c7789cd89259edf78930e8eb3a8b92e1567ae1a8d658"
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "metadata": {
      "interpreter": {
        "hash": "7f07ea6121238a4c2b48c7789cd89259edf78930e8eb3a8b92e1567ae1a8d658"
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6KKg_PXqpPN",
        "outputId": "34d6d4ab-3212-40e4-dd1b-3ede86aca844"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWhrzpVTc_WubTS3Ai0zgPTJYr25yp3WfOJ5zWc2Z51uAY3jTJFk4OY\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8kExtcIh-yy",
        "outputId": "daa34959-4c87-44f2-8b4a-91dd0206d08b"
      },
      "source": [
        "pip install neattext"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting neattext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/ac/f858b75b2d479d39cb43d92a21b892510b52240b27b48614a8da18e738b7/neattext-0.1.0-py3-none-any.whl (112kB)\n",
            "\r\u001b[K     |███                             | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 20kB 21.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 30kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 40kB 28.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 51kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 61kB 24.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 71kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 81kB 24.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 92kB 25.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 102kB 27.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 27.0MB/s \n",
            "\u001b[?25hInstalling collected packages: neattext\n",
            "Successfully installed neattext-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zak34AuW60-"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import tkinter\n",
        "from tkinter.filedialog import askopenfilename\n",
        "import string #Opérations courantes sur les chaînes\n",
        "import re   # pour utiliser  des expressions régulières ex:$\n",
        "import nltk #boites outils ntk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import neattext as nt\n",
        "import neattext.functions as nfx\n",
        "from neattext import TextCleaner as tc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrIs4Vn0W61V"
      },
      "source": [
        "#Cleaning & Preprocessing\n",
        "def process(text):\n",
        "# la normalisation\n",
        "    regex = re.compile(r'[إأٱآا]') #sauvegarder l'expression réguliere (r=expression reguliere)\n",
        "    text = re.sub(regex, 'ا', str(text)) #remblacer des expressions par d'autres dans varia texte\n",
        "    regex = re.compile(r'[ى]')\n",
        "    text = re.sub(regex, 'ي', str(text))\n",
        "    regex = re.compile(r'[ؤئ]')\n",
        "    text = re.sub(regex, 'ء', str(text))\n",
        "    text = re.sub('\\n', ' ', str(text))\n",
        "    text = re.sub(' و ', ' ', str(text))\n",
        "    text = re.sub(r'\\s*[A-Za-z]+\\b', '' , text)\n",
        "    text = text.rstrip()\n",
        "#supprimer les diacritiques\n",
        "    arabic_diacritics = re.compile(\"\"\"\n",
        "                             ّ    | # Shadda\n",
        "                             َ    | # Fatha\n",
        "                             ً    | # Tanwin Fath\n",
        "                             ُ    | # Damma\n",
        "                             ٌ    | # Tanwin Damm\n",
        "                             ِ    | # Kasra\n",
        "                             ٍ    | # Tanwin Kasr\n",
        "                             ْ    | # Sukun\n",
        "                             ـ     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)   #verbose: séparer visuellement les expre et ajouter des commentaires\n",
        "    text = re.sub(arabic_diacritics, '', text)\n",
        "    \n",
        "\n",
        "#supprimer les ponctuations\n",
        "    #liste des ponctuations arabe et anglais qu'on veut supprimer\n",
        "    arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''    # utiliser ''' :multiples caractére de chaine\n",
        "    english_punctuations = string.punctuation              #(!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~)\n",
        "    punctuations_list = arabic_punctuations + english_punctuations\n",
        "    #table de mappage\n",
        "    translator = str.maketrans('','', punctuations_list) # le 1er elem a remplacer/le 2eme le remplacement,3eme=supprimer\n",
        "    text= text.translate(translator) #chaine ou les caractere sont remplacé par d'autres dns table de mappage\n",
        "\n",
        "#supprimer les chaines répétés\n",
        "    text=re.sub(r'(.)\\1+', r'\\1', str(text)) \n",
        "\n",
        "#supprimer les mots vides\n",
        "    stopwords=nltk.corpus.stopwords.words('arabic') #les mots vides en arabe\n",
        "    txt=[word for word in text if word not in stopwords]\n",
        "\n",
        "#supprimer les émojis\n",
        "    myre = re.compile(u'['\n",
        "    u'\\U0001F300-\\U0001F64F'\n",
        "    u'\\U0001F680-\\U0001F6FF'     \n",
        "    u'\\u2600-\\u26FF\\u2700-\\u27BF]+', re.UNICODE)\n",
        "    text=myre.sub('', text)\n",
        "    \n",
        "    \n",
        "    return text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvlR6tuiW61b"
      },
      "source": [
        "filename='new_db.xlsx'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrPrOcR8W61e"
      },
      "source": [
        "#Importer le fichier excel\n",
        "data=pd.read_excel(filename) #filename:le chemin d'acces au fichier excel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lppk2WGVX9d3",
        "outputId": "35677713-2274-4e09-de6a-8281f34e9e77"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4q74R2UW61g"
      },
      "source": [
        "#Cleaning DB\n",
        "data['TWEET'] = data['TWEET'].apply(process)\n",
        "data['TWEET']=data['TWEET'].apply(nfx.remove_hashtags)\n",
        "data['TWEET']=data['TWEET'].apply(nfx.remove_userhandles)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na7IMeNTTUHI"
      },
      "source": [
        "index=[]\n",
        "for i in range(len(data)):\n",
        "  if data.iloc[i].TWEET=='':\n",
        "    index.append(i)\n",
        "\n",
        "for i in index:\n",
        "  data=data.drop(i)\n",
        "data = data.reset_index().drop('index',axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_sL2AJV4W61i",
        "outputId": "8b8aea0d-1426-4b12-e101-ad06c6b714cc"
      },
      "source": [
        "#Affichage des premiers elts\n",
        "data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>الاوليمبياد الجايه هكون لسه ف الكليه</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>عجز الموازنه وصل ل937 من الناتج المحلي يعني لس...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>كتنا نيله ف حظنا الهباب</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>جميعنا نريد تحقيق اهدافنا لكن تونس تالقت في حر...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الاوليمبياد نظامها مختلف ومواعيد المونديال مكا...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TWEET  LABEL\n",
              "0               الاوليمبياد الجايه هكون لسه ف الكليه      0\n",
              "1  عجز الموازنه وصل ل937 من الناتج المحلي يعني لس...      1\n",
              "2                            كتنا نيله ف حظنا الهباب      2\n",
              "3  جميعنا نريد تحقيق اهدافنا لكن تونس تالقت في حر...      3\n",
              "4  الاوليمبياد نظامها مختلف ومواعيد المونديال مكا...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gF9b7Yb6W61m",
        "scrolled": true,
        "outputId": "961f84bf-64cb-4e87-acdc-028ceb4c5a68"
      },
      "source": [
        "#Affichage des derniers elts\n",
        "data.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TWEET</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29947</th>\n",
              "      <td>اتمني تعملو بطاقات خاصة او ذهبية لعملاء الداءم...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29948</th>\n",
              "      <td>المشويات عندهم اطيب مشويات اكلتها بحياتي والاس...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29949</th>\n",
              "      <td>المطعم متاز لغايه من ناحيه تجهيزات المطعم وايض...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29950</th>\n",
              "      <td>جينا عندهم الساعة 10 باليل مافي احد اتبرع يشوف...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29951</th>\n",
              "      <td>اذا كان الي بالشارع التجاري اوه ماشاء اله واله...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   TWEET  LABEL\n",
              "29947  اتمني تعملو بطاقات خاصة او ذهبية لعملاء الداءم...      3\n",
              "29948  المشويات عندهم اطيب مشويات اكلتها بحياتي والاس...      3\n",
              "29949  المطعم متاز لغايه من ناحيه تجهيزات المطعم وايض...      3\n",
              "29950  جينا عندهم الساعة 10 باليل مافي احد اتبرع يشوف...      1\n",
              "29951  اذا كان الي بالشارع التجاري اوه ماشاء اله واله...      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoiE9Wq_siPE",
        "outputId": "ddabd4ad-6b11-4bd1-9342-118d77c41b8e"
      },
      "source": [
        "#Afficher les labels de la bd\n",
        "data.LABEL.unique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riI30SSasa_L"
      },
      "source": [
        "#Remplacer chaque label par un entier\n",
        "encode_dict = {}\n",
        "\n",
        "def encode_cat(x):\n",
        "    if x not in encode_dict.keys():\n",
        "        encode_dict[x]=len(encode_dict)\n",
        "    return encode_dict[x]\n",
        "\n",
        "data['LABEL'] = data['LABEL'].apply(lambda x: encode_cat(x))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRiie2x8W61p",
        "outputId": "808afa25-efac-48ab-e861-2b26943d9688"
      },
      "source": [
        "#Split data into random train(70%) and test(30%) subsets\n",
        "text_train, text_test, label_train, label_test = train_test_split(data.TWEET,data.LABEL,test_size=0.20, random_state=42)\n",
        "print(text_train.shape,text_test.shape,label_train.shape,label_test.shape)  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23961,) (5991,) (23961,) (5991,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sry5o4BwW61_"
      },
      "source": [
        "# GLOVE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XFTWb2H5ME6"
      },
      "source": [
        "# Preparation du model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-yxUqxaW62A"
      },
      "source": [
        "#from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD2atfN2qHyX"
      },
      "source": [
        "word2vec_output_file = 'vectors.txt.word2vec'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4oZcrtaqQkh",
        "outputId": "bd3ee845-ffbb-4e1f-99b8-c54b9ed0f9ae"
      },
      "source": [
        "# load the Stanford GloVe model\n",
        "%cd /content/drive/MyDrive/GloVe\n",
        "gl = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
        "%cd ..\n",
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/GloVe\n",
            "/content/drive/My Drive\n",
            "/content/drive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THVRcPZ_5YZp"
      },
      "source": [
        "# Machine learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH2ibkXd7Fgb"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mav0gaxK6jH4"
      },
      "source": [
        "# We will create a class that will contain our vocabulary and glove vectors and then it will transform every review \n",
        "#(sentence) to a vector representation as we describe previously.\n",
        "class Word2VecVectorizer:\n",
        "  def __init__(self, gl):\n",
        "    self.word_vectors = gl\n",
        "\n",
        "  def fit(self, data):\n",
        "    pass\n",
        "\n",
        "  def transform(self, data):\n",
        "    X = np.zeros((len(data), gl.vector_size))\n",
        "    n = 0\n",
        "    emptycount = 0\n",
        "    for sentence in data:\n",
        "      tokens = sentence.split()\n",
        "      vecs = []\n",
        "      m = 0\n",
        "      for word in tokens:\n",
        "        try:\n",
        "          # throws KeyError if word not found\n",
        "          vec = self.word_vectors.get_vector(word)\n",
        "          vecs.append(vec)\n",
        "          m += 1\n",
        "        except KeyError:\n",
        "          pass\n",
        "      if len(vecs) > 0:\n",
        "        vecs = np.array(vecs)\n",
        "        X[n] = vecs.mean(axis=0)\n",
        "      else:\n",
        "        emptycount += 1\n",
        "      n += 1\n",
        "    return X\n",
        "\n",
        "\n",
        "  def fit_transform(self, data):\n",
        "    self.fit(data)\n",
        "    return self.transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgSKU0MX6rxF"
      },
      "source": [
        "# Set a word vectorizer\n",
        "vectorizer = Word2VecVectorizer(gl)\n",
        "# Get the sentence embeddings for the train dataset\n",
        "text_train_glove = vectorizer.fit_transform(text_train)\n",
        "# Get the sentence embeddings for the test dataset\n",
        "text_test_glove = vectorizer.transform(text_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32y3PUCg6vLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb077bf-d098-4140-98d1-a8d4f6e5d48e"
      },
      "source": [
        "# create the model, train it, print scores\n",
        "clf = LogisticRegression(solver='liblinear')\n",
        "\n",
        "clf.fit(text_train_glove, label_train)\n",
        "\n",
        "tag_pred = clf.predict(text_test_glove)\n",
        "\n",
        "print(classification_report(label_test, tag_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.63      0.61       314\n",
            "           1       0.56      0.56      0.56      1184\n",
            "           2       0.54      0.33      0.41       701\n",
            "           3       0.67      0.87      0.76      2434\n",
            "           4       0.50      0.17      0.25       470\n",
            "           5       0.70      0.49      0.58       381\n",
            "           6       0.77      0.71      0.74       231\n",
            "           7       0.85      0.71      0.77       276\n",
            "\n",
            "    accuracy                           0.64      5991\n",
            "   macro avg       0.65      0.56      0.59      5991\n",
            "weighted avg       0.63      0.64      0.62      5991\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QjMeHTq603n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984af914-c8b5-4c90-c61d-9044753e88dd"
      },
      "source": [
        "# create the model, train it, print scores\n",
        "SVM=svm.SVC()\n",
        "\n",
        "SVM.fit(text_train_glove, label_train)\n",
        "\n",
        "tag_pred = SVM.predict(text_test_glove)\n",
        "\n",
        "print(classification_report(label_test, tag_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.84      0.69       314\n",
            "           1       0.59      0.66      0.63      1184\n",
            "           2       0.57      0.39      0.46       701\n",
            "           3       0.72      0.86      0.78      2434\n",
            "           4       0.63      0.20      0.31       470\n",
            "           5       0.75      0.49      0.59       381\n",
            "           6       0.81      0.71      0.76       231\n",
            "           7       0.91      0.71      0.79       276\n",
            "\n",
            "    accuracy                           0.68      5991\n",
            "   macro avg       0.70      0.61      0.63      5991\n",
            "weighted avg       0.68      0.68      0.66      5991\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK8LeeWE627o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb76376-c170-46b5-d362-508e05bd4865"
      },
      "source": [
        "# create the model, train it, print scores\n",
        "rf=RandomForestClassifier()\n",
        "\n",
        "rf.fit(text_train_glove, label_train)\n",
        "\n",
        "tag_pred = rf.predict(text_test_glove)\n",
        "\n",
        "print(classification_report(label_test, tag_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.69      0.63       314\n",
            "           1       0.78      0.73      0.75      1184\n",
            "           2       0.79      0.54      0.64       701\n",
            "           3       0.73      0.93      0.82      2434\n",
            "           4       0.78      0.48      0.59       470\n",
            "           5       0.73      0.57      0.64       381\n",
            "           6       0.85      0.56      0.68       231\n",
            "           7       0.81      0.57      0.67       276\n",
            "\n",
            "    accuracy                           0.74      5991\n",
            "   macro avg       0.76      0.63      0.68      5991\n",
            "weighted avg       0.75      0.74      0.73      5991\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOgWolIm69in",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf8759e-1813-49b6-a65c-571883e91057"
      },
      "source": [
        "nb=GaussianNB()\n",
        "\n",
        "nb.fit(text_train_glove, label_train)\n",
        "\n",
        "tag_pred = nb.predict(text_test_glove)\n",
        "\n",
        "print(classification_report(label_test, tag_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.69      0.58       314\n",
            "           1       0.31      0.77      0.44      1184\n",
            "           2       0.28      0.07      0.11       701\n",
            "           3       0.79      0.25      0.38      2434\n",
            "           4       0.19      0.18      0.18       470\n",
            "           5       0.44      0.46      0.45       381\n",
            "           6       0.44      0.66      0.53       231\n",
            "           7       0.35      0.63      0.45       276\n",
            "\n",
            "    accuracy                           0.40      5991\n",
            "   macro avg       0.41      0.46      0.39      5991\n",
            "weighted avg       0.52      0.40      0.37      5991\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST0eZzBI6fPW"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRAELyZ7uHPs"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import *\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Iux4mCvfzS"
      },
      "source": [
        "#create a word-to-index dictionary\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(text_train)\n",
        "X_test = tokenizer.texts_to_sequences(text_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCtB910KvkwO"
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 82\n",
        "\n",
        "#Add 0 at the end of the list until it reaches the max length\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IROfwITsvu6a"
      },
      "source": [
        "#Create an embedding matrix where each row number will correspond to the index of the word in the corpus\n",
        "embedding_matrix = np.zeros((vocab_size, 256))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  try:\n",
        "    embedding_vector = gl.get_vector(word)\n",
        "  except:\n",
        "    continue\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7--3gBcwLNa"
      },
      "source": [
        "#--------------------------------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TUhRdqYA3JY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86752129-3265-496e-c10f-280b822d9186"
      },
      "source": [
        "model1 = Sequential()\n",
        "embedding_layer = Embedding(vocab_size,256 , weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model1.add(embedding_layer)\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "model1.add(GRU(256, activation='sigmoid',recurrent_activation='sigmoid' , return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "model1.add(SimpleRNN(128))\n",
        "\n",
        "\n",
        "model1.add(Dense(8, activation='sigmoid'))\n",
        "model1.compile(optimizer='Adamax', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "model1.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 82, 256)           16857344  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 82, 256)           394752    \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8)                 1032      \n",
            "=================================================================\n",
            "Total params: 17,302,408\n",
            "Trainable params: 445,064\n",
            "Non-trainable params: 16,857,344\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYx0n-PHKFNr",
        "outputId": "c3e62d00-937a-4f1d-edf5-ce4aa25f4b33"
      },
      "source": [
        "history = model1.fit(X_train, label_train, batch_size=128, epochs=30, verbose=1, validation_split=0.2)\n",
        "\n",
        "score = model1.evaluate(X_test, label_test, verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "150/150 [==============================] - 61s 254ms/step - loss: 1.7784 - acc: 0.4006 - val_loss: 1.7148 - val_acc: 0.4271\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 35s 236ms/step - loss: 1.6985 - acc: 0.4323 - val_loss: 1.6372 - val_acc: 0.4381\n",
            "Epoch 3/30\n",
            "150/150 [==============================] - 36s 240ms/step - loss: 1.6044 - acc: 0.4372 - val_loss: 1.4829 - val_acc: 0.4646\n",
            "Epoch 4/30\n",
            "150/150 [==============================] - 35s 233ms/step - loss: 1.4663 - acc: 0.4684 - val_loss: 1.3508 - val_acc: 0.5416\n",
            "Epoch 5/30\n",
            "150/150 [==============================] - 37s 246ms/step - loss: 1.3321 - acc: 0.5343 - val_loss: 1.2491 - val_acc: 0.5642\n",
            "Epoch 6/30\n",
            "150/150 [==============================] - 37s 249ms/step - loss: 1.2069 - acc: 0.5722 - val_loss: 1.1410 - val_acc: 0.5961\n",
            "Epoch 7/30\n",
            "150/150 [==============================] - 36s 239ms/step - loss: 1.1370 - acc: 0.5981 - val_loss: 1.1005 - val_acc: 0.6149\n",
            "Epoch 8/30\n",
            "150/150 [==============================] - 37s 245ms/step - loss: 1.1068 - acc: 0.6097 - val_loss: 1.1067 - val_acc: 0.6105\n",
            "Epoch 9/30\n",
            "150/150 [==============================] - 36s 241ms/step - loss: 1.0559 - acc: 0.6312 - val_loss: 1.0839 - val_acc: 0.6186\n",
            "Epoch 10/30\n",
            "150/150 [==============================] - 36s 241ms/step - loss: 1.0003 - acc: 0.6477 - val_loss: 1.0066 - val_acc: 0.6476\n",
            "Epoch 11/30\n",
            "150/150 [==============================] - 39s 258ms/step - loss: 0.9690 - acc: 0.6612 - val_loss: 0.9780 - val_acc: 0.6612\n",
            "Epoch 12/30\n",
            "150/150 [==============================] - 36s 243ms/step - loss: 0.9341 - acc: 0.6768 - val_loss: 0.9655 - val_acc: 0.6656\n",
            "Epoch 13/30\n",
            "150/150 [==============================] - 37s 249ms/step - loss: 0.9046 - acc: 0.6829 - val_loss: 1.0048 - val_acc: 0.6401\n",
            "Epoch 14/30\n",
            "150/150 [==============================] - 36s 243ms/step - loss: 0.8907 - acc: 0.6904 - val_loss: 0.9418 - val_acc: 0.6716\n",
            "Epoch 15/30\n",
            "150/150 [==============================] - 36s 239ms/step - loss: 0.8725 - acc: 0.6955 - val_loss: 0.9045 - val_acc: 0.6843\n",
            "Epoch 16/30\n",
            "150/150 [==============================] - 36s 241ms/step - loss: 0.8366 - acc: 0.7101 - val_loss: 0.9190 - val_acc: 0.6889\n",
            "Epoch 17/30\n",
            "150/150 [==============================] - 36s 239ms/step - loss: 0.8217 - acc: 0.7094 - val_loss: 0.9072 - val_acc: 0.6900\n",
            "Epoch 18/30\n",
            "150/150 [==============================] - 37s 247ms/step - loss: 0.8169 - acc: 0.7172 - val_loss: 0.8948 - val_acc: 0.6910\n",
            "Epoch 19/30\n",
            "150/150 [==============================] - 38s 253ms/step - loss: 0.7853 - acc: 0.7283 - val_loss: 0.8591 - val_acc: 0.7062\n",
            "Epoch 20/30\n",
            "150/150 [==============================] - 35s 232ms/step - loss: 0.7679 - acc: 0.7321 - val_loss: 0.8531 - val_acc: 0.7077\n",
            "Epoch 21/30\n",
            "150/150 [==============================] - 37s 246ms/step - loss: 0.7433 - acc: 0.7365 - val_loss: 0.8600 - val_acc: 0.7046\n",
            "Epoch 22/30\n",
            "150/150 [==============================] - 35s 237ms/step - loss: 0.7378 - acc: 0.7398 - val_loss: 0.8593 - val_acc: 0.7014\n",
            "Epoch 23/30\n",
            "150/150 [==============================] - 36s 243ms/step - loss: 0.7131 - acc: 0.7530 - val_loss: 0.8440 - val_acc: 0.7121\n",
            "Epoch 24/30\n",
            "150/150 [==============================] - 36s 239ms/step - loss: 0.6916 - acc: 0.7619 - val_loss: 0.8437 - val_acc: 0.7160\n",
            "Epoch 25/30\n",
            "150/150 [==============================] - 36s 239ms/step - loss: 0.6726 - acc: 0.7702 - val_loss: 0.8582 - val_acc: 0.7071\n",
            "Epoch 26/30\n",
            "150/150 [==============================] - 36s 243ms/step - loss: 0.6601 - acc: 0.7702 - val_loss: 0.8121 - val_acc: 0.7275\n",
            "Epoch 27/30\n",
            "150/150 [==============================] - 37s 248ms/step - loss: 0.6562 - acc: 0.7774 - val_loss: 0.8371 - val_acc: 0.7275\n",
            "Epoch 28/30\n",
            "150/150 [==============================] - 35s 232ms/step - loss: 0.6289 - acc: 0.7884 - val_loss: 0.8006 - val_acc: 0.7290\n",
            "Epoch 29/30\n",
            "150/150 [==============================] - 37s 244ms/step - loss: 0.6297 - acc: 0.7850 - val_loss: 0.9137 - val_acc: 0.6873\n",
            "Epoch 30/30\n",
            "150/150 [==============================] - 34s 229ms/step - loss: 0.6002 - acc: 0.7978 - val_loss: 0.8004 - val_acc: 0.7311\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.8137 - acc: 0.7269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE4vsQRPjlvo",
        "outputId": "5e5f9366-546c-4c08-9483-2f0d6a7749b8"
      },
      "source": [
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score: 0.813711941242218\n",
            "Test Accuracy: 0.7269237041473389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XssBQy3zjpVo",
        "outputId": "2f522b63-5f8c-4497-94d3-afee5ca4a4b3"
      },
      "source": [
        "pred = np.argmax(model1.predict(X_test), axis=-1)\n",
        "print(classification_report(label_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.86      0.68       314\n",
            "           1       0.64      0.68      0.66      1184\n",
            "           2       0.49      0.50      0.50       701\n",
            "           3       0.84      0.85      0.85      2434\n",
            "           4       0.40      0.26      0.32       470\n",
            "           5       0.64      0.48      0.55       381\n",
            "           6       0.73      0.63      0.68       231\n",
            "           7       0.83      0.82      0.83       276\n",
            "\n",
            "    accuracy                           0.70      5991\n",
            "   macro avg       0.64      0.64      0.63      5991\n",
            "weighted avg       0.69      0.70      0.69      5991\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HmRf6g6Kexi"
      },
      "source": [
        "#----------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onyMwlc7VUtk"
      },
      "source": [
        "model2 = Sequential()\n",
        "embedding_layer = Embedding(vocab_size, 256, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model2.add(embedding_layer)\n",
        "\n",
        "model2.add(LSTM(1024))\n",
        "\n",
        "model2.add(Dense(8, activation='softmax'))\n",
        "model2.compile(optimizer='Adamax', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXpRpNJmW3FH",
        "outputId": "a8c220a7-8ee6-42db-8521-d918321fd58b"
      },
      "source": [
        "history = model2.fit(X_train, label_train, batch_size=128, epochs=100, verbose=1, validation_split=0.2)\n",
        "\n",
        "score = model2.evaluate(X_test, label_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "150/150 [==============================] - 22s 122ms/step - loss: 1.7990 - acc: 0.4067 - val_loss: 1.4860 - val_acc: 0.4367\n",
            "Epoch 2/100\n",
            "150/150 [==============================] - 17s 117ms/step - loss: 1.4536 - acc: 0.4674 - val_loss: 1.3816 - val_acc: 0.5122\n",
            "Epoch 3/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 1.3686 - acc: 0.5102 - val_loss: 1.3741 - val_acc: 0.4884\n",
            "Epoch 4/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 1.2928 - acc: 0.5416 - val_loss: 1.2978 - val_acc: 0.5602\n",
            "Epoch 5/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 1.2248 - acc: 0.5689 - val_loss: 1.2011 - val_acc: 0.5756\n",
            "Epoch 6/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 1.1616 - acc: 0.6002 - val_loss: 1.1501 - val_acc: 0.5900\n",
            "Epoch 7/100\n",
            "150/150 [==============================] - 17s 113ms/step - loss: 1.1302 - acc: 0.6006 - val_loss: 1.1652 - val_acc: 0.5992\n",
            "Epoch 8/100\n",
            "150/150 [==============================] - 17s 113ms/step - loss: 1.1140 - acc: 0.6098 - val_loss: 1.1076 - val_acc: 0.6076\n",
            "Epoch 9/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 1.0962 - acc: 0.6110 - val_loss: 1.1211 - val_acc: 0.6019\n",
            "Epoch 10/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 1.0724 - acc: 0.6203 - val_loss: 1.0920 - val_acc: 0.6249\n",
            "Epoch 11/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 1.0413 - acc: 0.6323 - val_loss: 1.0618 - val_acc: 0.6384\n",
            "Epoch 12/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.9994 - acc: 0.6510 - val_loss: 1.1018 - val_acc: 0.6315\n",
            "Epoch 13/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.9933 - acc: 0.6576 - val_loss: 1.0890 - val_acc: 0.6194\n",
            "Epoch 14/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.9578 - acc: 0.6732 - val_loss: 1.0705 - val_acc: 0.6376\n",
            "Epoch 15/100\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.9385 - acc: 0.6765 - val_loss: 1.0320 - val_acc: 0.6378\n",
            "Epoch 16/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.9154 - acc: 0.6828 - val_loss: 1.0285 - val_acc: 0.6509\n",
            "Epoch 17/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.8704 - acc: 0.7054 - val_loss: 1.0471 - val_acc: 0.6514\n",
            "Epoch 18/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.8843 - acc: 0.6989 - val_loss: 1.0541 - val_acc: 0.6497\n",
            "Epoch 19/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.8493 - acc: 0.7081 - val_loss: 0.9923 - val_acc: 0.6729\n",
            "Epoch 20/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.8107 - acc: 0.7298 - val_loss: 1.0178 - val_acc: 0.6635\n",
            "Epoch 21/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.8272 - acc: 0.7268 - val_loss: 0.9749 - val_acc: 0.6701\n",
            "Epoch 22/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.7687 - acc: 0.7462 - val_loss: 0.9849 - val_acc: 0.6893\n",
            "Epoch 23/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.7262 - acc: 0.7661 - val_loss: 0.9647 - val_acc: 0.6973\n",
            "Epoch 24/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.6802 - acc: 0.7853 - val_loss: 0.9623 - val_acc: 0.6987\n",
            "Epoch 25/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.6940 - acc: 0.7723 - val_loss: 0.9994 - val_acc: 0.6829\n",
            "Epoch 26/100\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.6465 - acc: 0.7927 - val_loss: 0.9475 - val_acc: 0.7146\n",
            "Epoch 27/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.6158 - acc: 0.8057 - val_loss: 0.9112 - val_acc: 0.7219\n",
            "Epoch 28/100\n",
            "150/150 [==============================] - 17s 113ms/step - loss: 0.5742 - acc: 0.8200 - val_loss: 0.9593 - val_acc: 0.7119\n",
            "Epoch 29/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.5590 - acc: 0.8258 - val_loss: 0.9364 - val_acc: 0.7131\n",
            "Epoch 30/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.4904 - acc: 0.8547 - val_loss: 0.9265 - val_acc: 0.7375\n",
            "Epoch 31/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.4724 - acc: 0.8587 - val_loss: 0.9588 - val_acc: 0.7342\n",
            "Epoch 32/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.4626 - acc: 0.8608 - val_loss: 0.9385 - val_acc: 0.7392\n",
            "Epoch 33/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.4551 - acc: 0.8611 - val_loss: 0.9019 - val_acc: 0.7450\n",
            "Epoch 34/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.4453 - acc: 0.8636 - val_loss: 0.9516 - val_acc: 0.7471\n",
            "Epoch 35/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.4319 - acc: 0.8713 - val_loss: 0.9413 - val_acc: 0.7373\n",
            "Epoch 36/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.4165 - acc: 0.8748 - val_loss: 0.9385 - val_acc: 0.7382\n",
            "Epoch 37/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.4285 - acc: 0.8718 - val_loss: 0.9282 - val_acc: 0.7354\n",
            "Epoch 38/100\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.4251 - acc: 0.8753 - val_loss: 0.9507 - val_acc: 0.7352\n",
            "Epoch 39/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.3956 - acc: 0.8798 - val_loss: 0.9420 - val_acc: 0.7450\n",
            "Epoch 40/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.3769 - acc: 0.8904 - val_loss: 0.9752 - val_acc: 0.7538\n",
            "Epoch 41/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.3945 - acc: 0.8827 - val_loss: 0.9440 - val_acc: 0.7475\n",
            "Epoch 42/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.3492 - acc: 0.8943 - val_loss: 1.0110 - val_acc: 0.7509\n",
            "Epoch 43/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.3458 - acc: 0.8978 - val_loss: 0.9930 - val_acc: 0.7423\n",
            "Epoch 44/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.3497 - acc: 0.8963 - val_loss: 1.0021 - val_acc: 0.7557\n",
            "Epoch 45/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.3139 - acc: 0.9071 - val_loss: 0.9712 - val_acc: 0.7557\n",
            "Epoch 46/100\n",
            "150/150 [==============================] - 18s 119ms/step - loss: 0.3008 - acc: 0.9119 - val_loss: 1.0400 - val_acc: 0.7473\n",
            "Epoch 47/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.3121 - acc: 0.9076 - val_loss: 1.0204 - val_acc: 0.7501\n",
            "Epoch 48/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.2982 - acc: 0.9134 - val_loss: 1.0785 - val_acc: 0.7555\n",
            "Epoch 49/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.2764 - acc: 0.9176 - val_loss: 1.0762 - val_acc: 0.7501\n",
            "Epoch 50/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.2770 - acc: 0.9176 - val_loss: 1.0871 - val_acc: 0.7561\n",
            "Epoch 51/100\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.2646 - acc: 0.9176 - val_loss: 1.1146 - val_acc: 0.7503\n",
            "Epoch 52/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.2625 - acc: 0.9220 - val_loss: 1.0774 - val_acc: 0.7561\n",
            "Epoch 53/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.2577 - acc: 0.9219 - val_loss: 1.1401 - val_acc: 0.7622\n",
            "Epoch 54/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.2061 - acc: 0.9373 - val_loss: 1.1523 - val_acc: 0.7642\n",
            "Epoch 55/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.2068 - acc: 0.9375 - val_loss: 1.1721 - val_acc: 0.7588\n",
            "Epoch 56/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1974 - acc: 0.9375 - val_loss: 1.1292 - val_acc: 0.7553\n",
            "Epoch 57/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1979 - acc: 0.9368 - val_loss: 1.1596 - val_acc: 0.7636\n",
            "Epoch 58/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.1935 - acc: 0.9409 - val_loss: 1.1602 - val_acc: 0.7386\n",
            "Epoch 59/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.2176 - acc: 0.9340 - val_loss: 1.1369 - val_acc: 0.7365\n",
            "Epoch 60/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.2095 - acc: 0.9372 - val_loss: 1.1843 - val_acc: 0.7630\n",
            "Epoch 61/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1968 - acc: 0.9389 - val_loss: 1.1737 - val_acc: 0.7651\n",
            "Epoch 62/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1931 - acc: 0.9414 - val_loss: 1.1993 - val_acc: 0.7546\n",
            "Epoch 63/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1930 - acc: 0.9418 - val_loss: 1.2379 - val_acc: 0.7653\n",
            "Epoch 64/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1837 - acc: 0.9443 - val_loss: 1.3103 - val_acc: 0.7653\n",
            "Epoch 65/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1602 - acc: 0.9504 - val_loss: 1.2563 - val_acc: 0.7619\n",
            "Epoch 66/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1497 - acc: 0.9531 - val_loss: 1.2631 - val_acc: 0.7615\n",
            "Epoch 67/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1672 - acc: 0.9485 - val_loss: 1.3499 - val_acc: 0.7475\n",
            "Epoch 68/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1813 - acc: 0.9430 - val_loss: 1.3281 - val_acc: 0.7367\n",
            "Epoch 69/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1796 - acc: 0.9447 - val_loss: 1.2928 - val_acc: 0.7686\n",
            "Epoch 70/100\n",
            "150/150 [==============================] - 17s 111ms/step - loss: 0.1530 - acc: 0.9525 - val_loss: 1.3410 - val_acc: 0.7609\n",
            "Epoch 71/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1581 - acc: 0.9501 - val_loss: 1.3933 - val_acc: 0.7611\n",
            "Epoch 72/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1507 - acc: 0.9537 - val_loss: 1.2598 - val_acc: 0.7538\n",
            "Epoch 73/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1596 - acc: 0.9525 - val_loss: 1.1829 - val_acc: 0.7549\n",
            "Epoch 74/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1704 - acc: 0.9496 - val_loss: 1.2567 - val_acc: 0.7615\n",
            "Epoch 75/100\n",
            "150/150 [==============================] - 18s 120ms/step - loss: 0.1639 - acc: 0.9496 - val_loss: 1.2996 - val_acc: 0.7571\n",
            "Epoch 76/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1392 - acc: 0.9567 - val_loss: 1.2975 - val_acc: 0.7632\n",
            "Epoch 77/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1310 - acc: 0.9588 - val_loss: 1.4131 - val_acc: 0.7567\n",
            "Epoch 78/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1473 - acc: 0.9589 - val_loss: 1.2847 - val_acc: 0.7632\n",
            "Epoch 79/100\n",
            "150/150 [==============================] - 17s 113ms/step - loss: 0.1420 - acc: 0.9581 - val_loss: 1.3053 - val_acc: 0.7563\n",
            "Epoch 80/100\n",
            "150/150 [==============================] - 17s 113ms/step - loss: 0.1273 - acc: 0.9615 - val_loss: 1.2406 - val_acc: 0.7586\n",
            "Epoch 81/100\n",
            "150/150 [==============================] - 17s 113ms/step - loss: 0.1335 - acc: 0.9589 - val_loss: 1.3117 - val_acc: 0.7590\n",
            "Epoch 82/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1251 - acc: 0.9623 - val_loss: 1.3700 - val_acc: 0.7540\n",
            "Epoch 83/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1356 - acc: 0.9607 - val_loss: 1.3461 - val_acc: 0.7517\n",
            "Epoch 84/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1298 - acc: 0.9601 - val_loss: 1.3729 - val_acc: 0.7603\n",
            "Epoch 85/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1252 - acc: 0.9621 - val_loss: 1.4781 - val_acc: 0.7603\n",
            "Epoch 86/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1204 - acc: 0.9649 - val_loss: 1.3512 - val_acc: 0.7626\n",
            "Epoch 87/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1331 - acc: 0.9603 - val_loss: 1.3690 - val_acc: 0.7580\n",
            "Epoch 88/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0987 - acc: 0.9715 - val_loss: 1.3689 - val_acc: 0.7594\n",
            "Epoch 89/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0925 - acc: 0.9711 - val_loss: 1.4868 - val_acc: 0.7519\n",
            "Epoch 90/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.1073 - acc: 0.9694 - val_loss: 1.4742 - val_acc: 0.7651\n",
            "Epoch 91/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0713 - acc: 0.9758 - val_loss: 1.5342 - val_acc: 0.7628\n",
            "Epoch 92/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0733 - acc: 0.9775 - val_loss: 1.5734 - val_acc: 0.7661\n",
            "Epoch 93/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0888 - acc: 0.9715 - val_loss: 1.4764 - val_acc: 0.7667\n",
            "Epoch 94/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0906 - acc: 0.9733 - val_loss: 1.5270 - val_acc: 0.7619\n",
            "Epoch 95/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0747 - acc: 0.9758 - val_loss: 1.4348 - val_acc: 0.7655\n",
            "Epoch 96/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0688 - acc: 0.9770 - val_loss: 1.5085 - val_acc: 0.7638\n",
            "Epoch 97/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0986 - acc: 0.9688 - val_loss: 1.5964 - val_acc: 0.7599\n",
            "Epoch 98/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0881 - acc: 0.9717 - val_loss: 1.5398 - val_acc: 0.7596\n",
            "Epoch 99/100\n",
            "150/150 [==============================] - 17s 113ms/step - loss: 0.0734 - acc: 0.9773 - val_loss: 1.4501 - val_acc: 0.7596\n",
            "Epoch 100/100\n",
            "150/150 [==============================] - 17s 112ms/step - loss: 0.0614 - acc: 0.9799 - val_loss: 1.5830 - val_acc: 0.7549\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.5770 - acc: 0.7615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdpxiAJwXBN_",
        "outputId": "2aaf067e-76bf-4ab5-8022-e2cbb92416f3"
      },
      "source": [
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score: 1.5770083665847778\n",
            "Test Accuracy: 0.7614755630493164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yia131MP2R9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ebbaab-01d2-4519-9743-12af15bd61e3"
      },
      "source": [
        "pred = np.argmax(model2.predict(X_test), axis=-1)\n",
        "print(classification_report(label_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.55      0.59       314\n",
            "           1       0.75      0.74      0.74      1184\n",
            "           2       0.65      0.64      0.65       701\n",
            "           3       0.84      0.89      0.86      2434\n",
            "           4       0.56      0.56      0.56       470\n",
            "           5       0.70      0.66      0.68       381\n",
            "           6       0.81      0.73      0.77       231\n",
            "           7       0.89      0.79      0.84       276\n",
            "\n",
            "    accuracy                           0.76      5991\n",
            "   macro avg       0.73      0.70      0.71      5991\n",
            "weighted avg       0.76      0.76      0.76      5991\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldAVxwVa-nhh"
      },
      "source": [
        "#------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwRMAfYRSDVh"
      },
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_size, 256, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model3.add(embedding_layer)\n",
        "\n",
        "\n",
        "model3.add(Conv1D(512, 1, activation='softsign'))\n",
        "model3.add(Conv1D(512, 1, activation='softsign'))\n",
        "model3.add(GlobalMaxPooling1D())\n",
        "model3.add(Dense(8, activation='softplus'))\n",
        "model3.compile(optimizer='Adamax', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMP17ZoDSaDc",
        "outputId": "9965cec6-8cd2-4d96-8ea7-22eff8b3c360"
      },
      "source": [
        "history = model3.fit(X_train, label_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n",
        "\n",
        "score = model3.evaluate(X_test, label_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "150/150 [==============================] - 4s 21ms/step - loss: 1.6150 - acc: 0.3821 - val_loss: 1.2126 - val_acc: 0.4555\n",
            "Epoch 2/10\n",
            "150/150 [==============================] - 3s 18ms/step - loss: 1.1528 - acc: 0.4696 - val_loss: 1.0839 - val_acc: 0.5074\n",
            "Epoch 3/10\n",
            "150/150 [==============================] - 3s 18ms/step - loss: 0.9995 - acc: 0.5638 - val_loss: 0.8561 - val_acc: 0.7085\n",
            "Epoch 4/10\n",
            "150/150 [==============================] - 3s 18ms/step - loss: 0.7604 - acc: 0.7358 - val_loss: 0.7946 - val_acc: 0.7242\n",
            "Epoch 5/10\n",
            "150/150 [==============================] - 3s 19ms/step - loss: 0.6829 - acc: 0.7628 - val_loss: 0.7559 - val_acc: 0.7363\n",
            "Epoch 6/10\n",
            "150/150 [==============================] - 3s 18ms/step - loss: 0.6192 - acc: 0.7907 - val_loss: 0.7318 - val_acc: 0.7492\n",
            "Epoch 7/10\n",
            "150/150 [==============================] - 3s 18ms/step - loss: 0.5613 - acc: 0.8116 - val_loss: 0.7226 - val_acc: 0.7501\n",
            "Epoch 8/10\n",
            "150/150 [==============================] - 3s 18ms/step - loss: 0.5061 - acc: 0.8349 - val_loss: 0.7024 - val_acc: 0.7634\n",
            "Epoch 9/10\n",
            "150/150 [==============================] - 3s 18ms/step - loss: 0.4665 - acc: 0.8525 - val_loss: 0.6906 - val_acc: 0.7680\n",
            "Epoch 10/10\n",
            "150/150 [==============================] - 3s 18ms/step - loss: 0.4214 - acc: 0.8736 - val_loss: 0.6787 - val_acc: 0.7759\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6887 - acc: 0.7698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPUYkPfOSa-w",
        "outputId": "cafbad31-70e3-46b5-b6a4-1664e4c2582d"
      },
      "source": [
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score: 0.6887174248695374\n",
            "Test Accuracy: 0.7698214054107666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C3q6fL4zTf0",
        "outputId": "26592146-85cc-49bd-a36f-63d77452b322"
      },
      "source": [
        "pred = np.argmax(model3.predict(X_test), axis=-1)\n",
        "print(classification_report(label_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.74      0.68       314\n",
            "           1       0.71      0.78      0.75      1184\n",
            "           2       0.67      0.63      0.65       701\n",
            "           3       0.84      0.88      0.86      2434\n",
            "           4       0.64      0.50      0.56       470\n",
            "           5       0.75      0.60      0.66       381\n",
            "           6       0.85      0.76      0.80       231\n",
            "           7       0.96      0.87      0.91       276\n",
            "\n",
            "    accuracy                           0.77      5991\n",
            "   macro avg       0.76      0.72      0.73      5991\n",
            "weighted avg       0.77      0.77      0.77      5991\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCDPJDJDS3wG"
      },
      "source": [
        "#--------------------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibuFERxH2rcw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}